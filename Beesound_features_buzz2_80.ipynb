{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Beesound_features_buzz2_80.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPcGA8EqbEwn"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxyhAV5ofClz"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import VotingClassifier, BaggingClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import auc, roc_curve\n",
        "from sklearn.metrics import classification_report\n",
        "from glob import glob\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYmGG7rBbNJb"
      },
      "source": [
        "# Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV2HLjQzlEoU"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxnqtIXckCg5"
      },
      "source": [
        "# Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Er_nG2fcyIP"
      },
      "source": [
        "# Functions to read all files and put into dictionaries\n",
        "def read_data_vn(root_path='', labels=[]):\n",
        "    data = {'dir': [],\n",
        "            'labels': []}\n",
        "    buzz_path = os.path.join(root_path)\n",
        "    for root, dirs, files in os.walk(buzz_path):\n",
        "        for item in files:\n",
        "            if item.endswith('.wav'):\n",
        "                x = os.path.join(root, item)\n",
        "                data['dir'].append(x)\n",
        "                data['labels'].append('0')\n",
        "    features = []\n",
        "    outputs = []\n",
        "\n",
        "    # Get extraction features: MFCC, Spectral, etc.\n",
        "    for filename, label in zip(data['dir'], data['labels']):\n",
        "        extract_feature = extract_mfcc(filename)\n",
        "        features.append(extract_feature)\n",
        "        outputs.append(label)\n",
        "    return features, outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWuVBTGgbvRP"
      },
      "source": [
        "# Functions to get extraction features\n",
        "\n",
        "def extract_mfcc(filename, n_mfcc=40):\n",
        "    y, sr = librosa.load(filename)\n",
        "    mfcc = librosa.feature.mfcc(y, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "    mfcc_mean = mfcc.mean(axis=1).T\n",
        "    mfcc_std = mfcc.std(axis=1).T\n",
        "    mfcc_feature = np.hstack([mfcc_mean, mfcc_std])\n",
        "    return mfcc_feature\n",
        "\n",
        "def extract_spectral_contrast(filename, n_bands=3):\n",
        "    y, sr = librosa.load(filename)\n",
        "    spec_con = librosa.feature.spectral_contrast(y=y, sr=sr, n_bands=n_bands)\n",
        "    spec_con_mean = spec_con.mean(axis=1).T\n",
        "    spec_con_std = spec_con.std(axis=1).T\n",
        "    spec_con_feature = np.hstack([spec_con_mean, spec_con_std])\n",
        "    # features = np.hstack([features, spec_con_feature] if features is not None else spec_con_feature)\n",
        "    return spec_con_feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dacTWyC7bvRQ"
      },
      "source": [
        "# Functions to read all files and put into dictionaries\n",
        "def read_data(root_path='E:\\\\Download\\\\sounds\\BUZZ1\\\\sounds\\\\BUZZ2\\\\validation',\n",
        "              labels=[]):\n",
        "    data = {'dir': [],\n",
        "            'labels': []}\n",
        "    for label in labels:\n",
        "        buzz_path = os.path.join(root_path, label)\n",
        "        for root, dirs, files in os.walk(buzz_path):\n",
        "            for item in files:\n",
        "                if item.endswith('.wav'):\n",
        "                    x = os.path.join(root, item)\n",
        "                    data['dir'].append(x)\n",
        "                    if label == 'bee':\n",
        "                        data['labels'].append('bee')\n",
        "                    if label == 'noise':\n",
        "                        data['labels'].append('noise')\n",
        "                    elif label=='cricket':\n",
        "                        data['labels'].append('cricket')\n",
        "    return data\n",
        "\n",
        "# When we have dictionary, we get extraction features\n",
        "def get_extraction_data(root_path, subset='train', method='mfcc'):\n",
        "    labels=['bee', 'cricket', 'noise']\n",
        "    data = read_data(os.path.join(root_path, subset), labels)\n",
        "    features = []\n",
        "    outputs = []\n",
        "\n",
        "    # Get extraction features: MFCC, Spectral, etc.\n",
        "    for filename, label in zip(data['dir'], data['labels']):\n",
        "        if method == 'mfcc':\n",
        "            extract_feature = extract_mfcc(filename)\n",
        "        elif method == 'spectral':\n",
        "            extract_feature = extract_spectral_contrast(filename)\n",
        "        elif method == 'melspectrogram':\n",
        "            y, sr = librosa.load(filename)\n",
        "            extract_feature = np.mean(librosa.feature.melspectrogram(y, sr=sr).T,axis=0)\n",
        "        else:\n",
        "            y, sr = librosa.load(filename)\n",
        "            s = np.abs(librosa.stft(y))\n",
        "            extract_feature = np.mean(librosa.feature.chroma_stft(S=s, sr=sr).T,axis=0)\n",
        "        features.append(extract_feature)\n",
        "        outputs.append(label)\n",
        "    return features, outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46AUoCq9bvRR"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "# PUT IT ALL TOGETHER\n",
        "def get_all_data(root_path='E:\\\\Download\\\\sounds\\\\BUZZ2\\\\'):\n",
        "    features, outputs = get_extraction_data(root_path, subset='train')\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le.fit(outputs)\n",
        "\n",
        "    X_train = np.asarray(features)\n",
        "    y_train = le.transform(outputs)\n",
        "    y_train = np.asarray(y_train)\n",
        "\n",
        "    test_features, test_outputs = get_extraction_data(root_path, subset='test')\n",
        "    X_test = np.asarray(test_features)\n",
        "    y_test = le.transform(test_outputs)\n",
        "    y_test = np.asarray(y_test)\n",
        "\n",
        "    val_features, val_outputs = get_extraction_data(root_path, subset='val')\n",
        "    X_val = np.asarray(val_features)\n",
        "    y_val = le.transform(val_outputs)\n",
        "    y_val = np.asarray(y_val)\n",
        "\n",
        "    np.save('2_X_train', X_train)\n",
        "    np.save('2_y_train', y_train)\n",
        "    np.save('2_X_val', X_val)\n",
        "    np.save('2_y_val', y_val)\n",
        "    np.save('2_X_test', X_test)\n",
        "    np.save('2_y_test', y_test)\n",
        "    return X_train, y_train, X_test, y_test, X_val, y_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foriM_ijkGKD"
      },
      "source": [
        "# Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXOjU2mFbvRT"
      },
      "source": [
        "#if we do have the saved data, we run all files\n",
        "# X_train, y_train, X_test, y_test, X_val, y_val = get_all_data()\n",
        "\n",
        "# OR if we have saved data, we load it\n",
        "X_train = np.load('2_X_train_mfcc.npy')\n",
        "X_test = np.load('2_X_test_mfcc.npy')\n",
        "X_val = np.load('2_X_val_mfcc.npy')\n",
        "\n",
        "y_train = np.load('2_y_train_mfcc.npy')\n",
        "y_test = np.load('2_y_test_mfcc.npy')\n",
        "y_val = np.load('2_y_val_mfcc.npy')\n",
        "\n",
        "X_train_vn, y_train_vn = read_data_vn(root_path='/content/drive/MyDrive/Dataset/Sounds/Bee_VN_add_BUZZ2/train_200', labels=['0'])\n",
        "X_test_vn, y_test_vn = read_data_vn(root_path='/content/drive/MyDrive/Dataset/Sounds/Bee_VN_add_BUZZ2/test_800', labels=['0'])\n",
        "X_val_vn, y_val_vn = read_data_vn(root_path='/content/drive/MyDrive/Dataset/Sounds/Bee_VN_add_BUZZ2/val_1600', labels=['0'])\n",
        "\n",
        "X_train_vn = np.concatenate([X_train, X_train_vn], axis=0)\n",
        "X_test_vn = np.concatenate([X_test, X_test_vn], axis=0)\n",
        "X_val_vn = np.concatenate([X_val, X_val_vn], axis=0)\n",
        "y_train_vn = np.concatenate([y_train, y_train_vn], axis=0)\n",
        "y_test_vn = np.concatenate([y_test, y_test_vn], axis=0)\n",
        "y_val_vn = np.concatenate([y_val, y_val_vn], axis=0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhNr5kIlbvRX"
      },
      "source": [
        "X = np.concatenate([X_train, X_test], axis=0)\n",
        "y = np.concatenate([y_train, y_test], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqF5XhQ6kIrz"
      },
      "source": [
        "# Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeWAGio9kMrO"
      },
      "source": [
        "## SelectFromModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMVdgDcR_SWG"
      },
      "source": [
        "# from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
        "# from sklearn.feature_selection import SelectFromModel\n",
        "# clf = ExtraTreesClassifier(n_estimators=100)\n",
        "# clf = clf.fit(X, y)\n",
        "# model = SelectFromModel(estimator=clf, prefit=True,\n",
        "                        # max_features=0.5)\n",
        "\n",
        "# X_train = model.transform(X_train)\n",
        "# X_val = model.transform(X_val)\n",
        "# X_test = model.transform(X_test)\n",
        "# X = model.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj6NDWBM1qMS"
      },
      "source": [
        "## RFECV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGZd5SAFxv-n"
      },
      "source": [
        "# from sklearn.feature_selection import RFECV\n",
        "# from sklearn.ensemble import ExtraTreesClassifier\n",
        "# rfe = RFECV(estimator=ExtraTreesClassifier(),\n",
        "#             cv=5, scoring='accuracy', step=0.3)\n",
        "# rfe.fit(X_train, y_train)\n",
        "# X_train = rfe.transform(X_train)\n",
        "# X_val = rfe.transform(X_val)\n",
        "# X_test = rfe.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTQneXqUpXK1"
      },
      "source": [
        "## Select KBest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0I0XHq7pZAk"
      },
      "source": [
        "# from sklearn.feature_selection import SelectKBest, chi2\n",
        "# kbest = SelectKBest(chi2, k=20).fit(X, y)\n",
        "\n",
        "# X = kbest.transform(X)\n",
        "# X_train = kbest.transform(X_train)\n",
        "# X_test = kbest.transform(X_test)\n",
        "# X_val = kbest.transform(X_val)\n",
        "# X_train = SelectKBest(chi2, k=20).fit_transform(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdUyw0EEjvVz"
      },
      "source": [
        "## Sequential Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d4XKJyjj4IP"
      },
      "source": [
        "# from sklearn.feature_selection import SequentialFeatureSelector\n",
        "\n",
        "# clf = ExtraTreesClassifier(random_state=42)\n",
        "# sfs = SequentialFeatureSelector(clf,\n",
        "#                                 n_features_to_select=3)\n",
        "# sfs.fit(X, y)\n",
        "\n",
        "# X = sfs.transform(X)\n",
        "# X_train = sfs.transform(X_train)\n",
        "# X_test = sfs.transform(X_test)\n",
        "# X_val = sfs.transform(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkF1vS0fCh-L"
      },
      "source": [
        "# Ensemble feature selections NOT FINISH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O95X55du7nA5"
      },
      "source": [
        "# from sklearn.feature_selection import RFE\n",
        "# from sklearn.feature_selection import SelectKBest\n",
        "# from sklearn.feature_selection import f_classif\n",
        "# from sklearn.pipeline import Pipeline\n",
        "\n",
        "# models = []\n",
        "# fs = SelectKBest(score_func=f_classif, k=20)\n",
        "# models.append(('fs', fs))\n",
        "# rfe = RFE(estimator=ExtraTreesClassifier(), n_features_to_select=20)\n",
        "# models.append(('rfe', rfe))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxEiZMg9l4AG"
      },
      "source": [
        "# Tuning models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUsy1JmubvRV"
      },
      "source": [
        "def search_for_best_models(clf, params, X_train, y_train, X_test, y_test,\n",
        "                           scoring='accuracy', cv=5):\n",
        "    X = np.concatenate([X_train, X_test], axis=0)\n",
        "    y = np.concatenate([y_train, y_test], axis=0)\n",
        "    optimal_models = RandomizedSearchCV(clf,\n",
        "                            param_distributions=params,\n",
        "                            cv=cv, n_jobs=-1,\n",
        "                            random_state=42,\n",
        "                            n_iter=10,\n",
        "                            scoring=scoring)\n",
        "    optimal_models.fit(X, y)\n",
        "\n",
        "    return (optimal_models.best_params_,\n",
        "            optimal_models.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pp7zL6vXsyX"
      },
      "source": [
        "#SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUZfTPT3XP7V"
      },
      "source": [
        "import scipy\n",
        "svm_params = {'C': scipy.stats.expon(scale=1.),\n",
        "              'gamma': scipy.stats.expon(scale=.1),\n",
        "              'kernel': ['rbf'], 'class_weight':[None]}\n",
        "optimal_params, _ = search_for_best_models(SVC(),\n",
        "                                           params=svm_params,\n",
        "                                           X_train=X_train,\n",
        "                                           y_train=y_train,\n",
        "                                           X_test=X_test,\n",
        "                                           y_test=y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTFT-TSU716r"
      },
      "source": [
        "optimal_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XNHXYZt7yaT"
      },
      "source": [
        "model = SVC(C=optimal_params['C'],\n",
        "          gamma=optimal_params['gamma'],\n",
        "          kernel=optimal_params['kernel'],\n",
        "          class_weight=optimal_params['class_weight'],\n",
        "          random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_predict = model.predict(X_val)\n",
        "print('Accuracy Score is {:.5}'.format(accuracy_score(y_val, y_predict)))\n",
        "print(classification_report(y_val, y_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0_Fe-Oal9xN"
      },
      "source": [
        "#Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qIhRkDQbvRW"
      },
      "source": [
        "params = {\"max_depth\": ['None', 2, 3, 5, 10, 15],\n",
        "        \"min_samples_split\": [2, 3, 5, 10],\n",
        "        \"min_samples_leaf\": [1, 2, 3, 5],\n",
        "      }\n",
        "\n",
        "optimal_params, optimal_models = search_for_best_models(clf=DecisionTreeClassifier(),\n",
        "                                                         params=params,\n",
        "                                                         X_train=X_train,\n",
        "                                                         y_train=y_train,\n",
        "                                                        X_test=X_test,\n",
        "                                                        y_test=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0_ce0I8xM4g"
      },
      "source": [
        "print(optimal_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqL5yhl6bvRW"
      },
      "source": [
        "model = DecisionTreeClassifier(max_depth=optimal_params['max_depth'],\n",
        "                               min_samples_split=optimal_params['min_samples_split'],\n",
        "                               min_samples_leaf=optimal_params['min_samples_leaf'],\n",
        "                               random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpRQu6TMbvRX"
      },
      "source": [
        "model.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgCcd01ibvRX"
      },
      "source": [
        "y_preds = model.predict(X_val)\n",
        "print(classification_report(y_true=y_val, y_pred=y_preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-y3R8chdrEF"
      },
      "source": [
        "## ROC CURVE Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8YGZ2KjdgV2"
      },
      "source": [
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "n_classes = 3\n",
        "\n",
        "y_score = model.predict_proba(X_val)\n",
        "# y_score = model.decision_function(X_test)\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "y_val_dummies = pd.get_dummies(y_val, drop_first=False).values\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_val_dummies[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 9))\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "ax.set_xlim([0.0, 1.0])\n",
        "ax.set_ylim([0.0, 1.05])\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('Receiver operating characteristic example')\n",
        "for i in range(n_classes):\n",
        "    ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n",
        "ax.legend(loc=\"best\")\n",
        "ax.grid(alpha=.4)\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_hUBcqLmjEI"
      },
      "source": [
        "# Extra Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J5k9FkQbvRY"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "params = {\n",
        "    'n_estimators':[50, 100, 200,\n",
        "                    300, 500, 1000],\n",
        "    \"max_features\": ['auto', 'sqrt', 'None', 2, 4, 5, 9, 10, 15, 18],\n",
        "    'max_depth':[None, 2, 5, 8, 10],\n",
        "    'min_samples_split': [2, 3, 5],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4U7sf_NbvRY"
      },
      "source": [
        "optimal_params, optimal_models = search_for_best_models(\n",
        "    clf=RandomForestClassifier(), params=params,\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    X_test=X_test, y_test=y_test)\n",
        "model = ExtraTreesClassifier(n_estimators=optimal_params['n_estimators'],\n",
        "                              max_depth=optimal_params['max_depth'],\n",
        "                              max_features=optimal_params['max_features'],\n",
        "                               min_samples_leaf=optimal_params['min_samples_split'],\n",
        "                               random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM7TbXlPxYSM"
      },
      "source": [
        "print(optimal_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIKv9WTSbvRY"
      },
      "source": [
        "model.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiVsbyedbvRZ"
      },
      "source": [
        "y_preds = model.predict(X_val)\n",
        "print(classification_report(y_true=y_val, y_pred=y_preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhggR7oxd5VO"
      },
      "source": [
        "## ROC CURVE Extra Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNwpSf8BiDgU"
      },
      "source": [
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "n_classes = 3\n",
        "\n",
        "y_score = model.predict_proba(X_val)\n",
        "# y_score = model.decision_function(X_test)\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "y_val_dummies = pd.get_dummies(y_val, drop_first=False).values\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_val_dummies[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 9))\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "ax.set_xlim([0.0, 1.0])\n",
        "ax.set_ylim([0.0, 1.05])\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('Receiver operating characteristic example')\n",
        "for i in range(n_classes):\n",
        "    ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n",
        "ax.legend(loc=\"best\")\n",
        "ax.grid(alpha=.4)\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj9YxjcZd2Sm"
      },
      "source": [
        "#RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgN2lPr9bvRZ"
      },
      "source": [
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "params = {\n",
        "    'n_estimators':[50, 100, 200,\n",
        "                    300, 500, 1000],\n",
        "    \"max_features\": ['auto', 'sqrt', 'None', 2, 4, 5, 9, 10, 15, 18],\n",
        "    'max_depth':[None, 2, 5, 8, 10],\n",
        "    'min_samples_split': [2, 3, 5],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "optimal_params, optimal_models = search_for_best_models(\n",
        "    clf=RandomForestClassifier(), params=params,\n",
        "    X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
        "model = RandomForestClassifier(n_estimators=optimal_params['n_estimators'],\n",
        "                              max_depth=optimal_params['max_depth'],\n",
        "                              max_features=optimal_params['max_features'],\n",
        "                               min_samples_leaf=optimal_params['min_samples_split'],\n",
        "                               random_state=42)\n",
        "\n",
        "model.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc4TNUpgxcS7"
      },
      "source": [
        "print(optimal_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3qlCYDtbvRa"
      },
      "source": [
        "y_predict = model.predict(X_val)\n",
        "print('Accuracy Score is {:.5}'.format(accuracy_score(y_val, y_predict)))\n",
        "print(classification_report(y_val, y_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKVPNB8neT3Q"
      },
      "source": [
        "## ROC CURVE RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2JZUONgiHap"
      },
      "source": [
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "n_classes = 3\n",
        "\n",
        "y_score = model.predict_proba(X_val)\n",
        "# y_score = model.decision_function(X_test)\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "y_val_dummies = pd.get_dummies(y_val, drop_first=False).values\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_val_dummies[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 9))\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "ax.set_xlim([0.0, 1.0])\n",
        "ax.set_ylim([0.0, 1.05])\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('Receiver operating characteristic example')\n",
        "for i in range(n_classes):\n",
        "    ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n",
        "ax.legend(loc=\"best\")\n",
        "ax.grid(alpha=.4)\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhenCcCDnMrs"
      },
      "source": [
        "#XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrWMZ6BNbvRa"
      },
      "source": [
        "param_grid = {\n",
        "     'max_depth': [2, 4, 5, 8, 12, 15],\n",
        "     'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
        "     'gamma': [0.01, 0.1, 0.25, 0.5],\n",
        "     'reg_lambda': [10.0, 20., 50., 100.],\n",
        "      'scale_pos_weight': [1]}\n",
        "optimal_params = RandomizedSearchCV(\n",
        "    estimator=XGBClassifier(\n",
        "    seed=42, subsample=0.9,\n",
        "    colsample_bytree=0.5),\n",
        "    param_distributions=param_grid,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1, cv=5)\n",
        "optimal_params.fit(X, y)\n",
        "params = optimal_params.best_params_\n",
        "model = XGBClassifier(\n",
        "                        gamma=params['gamma'],\n",
        "                        learn_rate=params['learning_rate'],\n",
        "                        max_depth=params['max_depth'],\n",
        "                        reg_lambda=params['reg_lambda'],\n",
        "                        scale_pos_weight=1,\n",
        "                        subsample=0.9,\n",
        "                        colsample_bytree=0.5,\n",
        "                        seed=42,\n",
        "                        n_jobs=4)\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4yl9ZJXxfsp"
      },
      "source": [
        "print(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz9238_ebvRa"
      },
      "source": [
        "y_predict = model.predict(X_val)\n",
        "print('Accuracy Score is {:.5}'.format(accuracy_score(y_val, y_predict)))\n",
        "print(classification_report(y_val, y_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRac2qnhnPaw"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggys-2lF-6th"
      },
      "source": [
        "param_dist = {\n",
        "    'penalty' : ['None', 'l1', 'l2'],\n",
        "    'C' : [0.001, 0.01, 0.1, 0.5, 1.0, 1.5, 2.0]\n",
        "}\n",
        "lr_model = LogisticRegression(multi_class='multinomial',\n",
        "                           solver='lbfgs')\n",
        "optimal_params, optimal_model = search_for_best_models(clf=lr_model,\n",
        "                                                       X_train=X_train,\n",
        "                                                       y_train=y_train,\n",
        "                                                       X_test=X_test,\n",
        "                                                       y_test=y_test,\n",
        "                                                       params=param_dist)\n",
        "lr_model = LogisticRegression(multi_class='multinomial',\n",
        "                           solver='lbfgs',\n",
        "                           penalty=optimal_params['penalty'],\n",
        "                           C=optimal_params['C'])\n",
        "lr_model.fit(X, y)\n",
        "y_preds = lr_model.predict(X_val)\n",
        "print(classification_report(y_true=y_val,\n",
        "                            y_pred=y_preds))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPjLpDLbxlyQ"
      },
      "source": [
        "print(optimal_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrTEoYGYeeV3"
      },
      "source": [
        "## ROC CURVE Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra4KqTkiiJ7_"
      },
      "source": [
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "n_classes = 3\n",
        "\n",
        "y_score = lr_model.predict_proba(X_val)\n",
        "# y_score = model.decision_function(X_test)\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "y_val_dummies = pd.get_dummies(y_val, drop_first=False).values\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_val_dummies[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 9))\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "ax.set_xlim([0.0, 1.0])\n",
        "ax.set_ylim([0.0, 1.05])\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('Receiver operating characteristic example')\n",
        "for i in range(n_classes):\n",
        "    ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n",
        "ax.legend(loc=\"best\")\n",
        "ax.grid(alpha=.4)\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIDNBZc8nTNW"
      },
      "source": [
        "# GradientBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SqnJMyV_FoX"
      },
      "source": [
        "np.random.seed(42)\n",
        "params = {\n",
        "    'loss': ['deviance', 'exponential'],\n",
        "    'learning_rate': [0.001, 0.01, 0.1, 0.5, 1., 2.],\n",
        "    'n_estimators':[50, 100, 200,\n",
        "                    300, 500, 1000],\n",
        "    \"max_features\": ['auto', 'sqrt', 'None', 2, 4, 5, 9, 10, 15, 18],\n",
        "    'max_depth':[None, 2, 5, 8, 10],\n",
        "    'min_samples_split': [2, 3, 5],\n",
        "    'criterion': ['friedman_mse', 'mse']\n",
        "}\n",
        "optimal_params, optimal_models = search_for_best_models(\n",
        "    clf=GradientBoostingClassifier(), params=params,\n",
        "    X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
        "model = GradientBoostingClassifier(n_estimators=optimal_params['n_estimators'],\n",
        "                        loss=optimal_params['loss'],\n",
        "                        learning_rate=optimal_params['learning_rate'],\n",
        "                        max_depth=optimal_params['max_depth'],\n",
        "                        max_features=optimal_params['max_features'],\n",
        "                        min_samples_leaf=optimal_params['min_samples_split'],\n",
        "                        random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_predict = model.predict(X_val)\n",
        "print('Accuracy Score is {:.5}'.format(accuracy_score(y_val, y_predict)))\n",
        "print(classification_report(y_val, y_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzjykTIexptb"
      },
      "source": [
        "print(optimal_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYuLblbreoyn"
      },
      "source": [
        "## ROC CURVE Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI4X0VhDiMHe"
      },
      "source": [
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "n_classes = 3\n",
        "\n",
        "y_score = model.predict_proba(X_val)\n",
        "# y_score = model.decision_function(X_test)\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "y_val_dummies = pd.get_dummies(y_val, drop_first=False).values\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_val_dummies[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 9))\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "ax.set_xlim([0.0, 1.0])\n",
        "ax.set_ylim([0.0, 1.05])\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('Receiver operating characteristic example')\n",
        "for i in range(n_classes):\n",
        "    ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n",
        "ax.legend(loc=\"best\")\n",
        "ax.grid(alpha=.4)\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzk4tXe44_Fc"
      },
      "source": [
        "# KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GStR3TTt5BsA"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "params = {\n",
        "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree'],\n",
        "}\n",
        "optimal_params, optimal_models = search_for_best_models(clf=KNeighborsClassifier(),\n",
        "                                                        params=params,\n",
        "                                                        X_train=X_train,\n",
        "                                                        y_train=y_train,\n",
        "                                                        X_test=X_test,\n",
        "                                                        y_test=y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC49fjbqxsrd"
      },
      "source": [
        "print(optimal_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzMvc4xP7glk"
      },
      "source": [
        "neigh = KNeighborsClassifier(\n",
        "    n_neighbors=optimal_params['n_neighbors'],\n",
        "    algorithm=optimal_params['algorithm']\n",
        ")\n",
        "neigh.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8HZL7Ib7oZs"
      },
      "source": [
        "y_predict = neigh.predict(X_val)\n",
        "print('Accuracy Score is {:.5}'.format(accuracy_score(y_val, y_predict)))\n",
        "print(classification_report(y_val, y_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEKDKJv0evyW"
      },
      "source": [
        "## ROC CURVE KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiauw6ZaiODR"
      },
      "source": [
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "n_classes = 3\n",
        "\n",
        "y_score = model.predict_proba(X_val)\n",
        "# y_score = model.decision_function(X_test)\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "y_val_dummies = pd.get_dummies(y_val, drop_first=False).values\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_val_dummies[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 9))\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "ax.set_xlim([0.0, 1.0])\n",
        "ax.set_ylim([0.0, 1.05])\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('Receiver operating characteristic example')\n",
        "for i in range(n_classes):\n",
        "    ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n",
        "ax.legend(loc=\"best\")\n",
        "ax.grid(alpha=.4)\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDmgV_RWnWKT"
      },
      "source": [
        "# MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjnX9U6abvRb"
      },
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras import backend as K\n",
        "# from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "input_train = X_train\n",
        "target_train = to_categorical(y_train)\n",
        "input_val = X_val\n",
        "target_val = to_categorical(y_val)\n",
        "input_test = X_test\n",
        "target_test = to_categorical(y_test)\n",
        "\n",
        "input_layer = keras.layers.Input(shape=(input_train.shape[1]))\n",
        "dense = keras.layers.Dense(256, activation = 'relu')(input_layer)\n",
        "dense = keras.layers.Dense(256, activation = 'relu')(dense)\n",
        "dense = keras.layers.Dropout(0.6)(dense)\n",
        "dense = keras.layers.Dense(128, activation = 'relu')(dense)\n",
        "dense = keras.layers.Dropout(0.5)(dense)\n",
        "dense = keras.layers.Dense(3, activation = 'softmax')(dense)\n",
        "model = Model(inputs=input_layer, outputs=dense)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTSdPqV9bvRb"
      },
      "source": [
        "model.fit(input_train,\n",
        "          target_train,\n",
        "          batch_size=256,\n",
        "          validation_data=(input_test, target_test),\n",
        "          epochs=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujCs2WX7bvRc"
      },
      "source": [
        "model.evaluate(input_val,\n",
        "               target_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yA15hrTnY5g"
      },
      "source": [
        "# VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jngz5R5bvRc"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "# from tensorlow.keras import regularizers\n",
        "from tensorflow.keras import regularizers\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_reshape = scaler.transform(X_train)\n",
        "X_test_reshape = scaler.transform(X_test)\n",
        "X_val_reshape = scaler.transform(X_val)\n",
        "\n",
        "X_train_vn_reshape = scaler.transform(X_train_vn)\n",
        "X_test_vn_reshape = scaler.transform(X_test_vn)\n",
        "X_val_vn_reshape = scaler.transform(X_val_vn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5uzQt0WbvRc"
      },
      "source": [
        "original_dim = X_train_reshape.shape[1]\n",
        "intermediate_dim = 32\n",
        "latent_dim = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzHNVp6GbvRd"
      },
      "source": [
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_sigma = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
        "                              mean=0., stddev=0.1)\n",
        "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
        "\n",
        "inputs = keras.Input(shape=(original_dim,))\n",
        "h = layers.Dense(16, activation='relu')(inputs)\n",
        "# h = layers.Dense(256, activation='relu')(h)\n",
        "h = layers.Dense(intermediate_dim, activation='elu')(h)\n",
        "z_mean = layers.Dense(latent_dim)(h)\n",
        "z_log_sigma = layers.Dense(latent_dim)(h)\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
        "\n",
        "# Create encoder\n",
        "encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
        "# Create decoder\n",
        "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
        "x = layers.Dense(intermediate_dim, activation='elu')(latent_inputs)\n",
        "# x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dense(16, activation='elu')(x)\n",
        "outputs = layers.Dense(original_dim, activation='linear')(x)\n",
        "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
        "# instantiate VAE model\n",
        "outputs = decoder(encoder(inputs)[2])\n",
        "vae = keras.Model(inputs, outputs, name='vae_mlp')\n",
        "\n",
        "# reconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\n",
        "reconstruction_loss = keras.losses.mean_squared_error(inputs, outputs)\n",
        "reconstruction_loss *= original_dim\n",
        "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam', metrics=['mse'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSSMKmFsbvRd"
      },
      "source": [
        "vae.fit(X_train_reshape, X_train_reshape,\n",
        "        epochs=100,\n",
        "        batch_size=256,\n",
        "        validation_split=0.1,\n",
        "        verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DacqqUaKbvRd"
      },
      "source": [
        "labels = {\n",
        "    0: 'Bee',\n",
        "    1: 'Cricket',\n",
        "    2: 'Noise'\n",
        "}\n",
        "\n",
        "print(labels[int(y[0])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4uHD3fsbvRd"
      },
      "source": [
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "X_encoded = encoder.predict(X_train_reshape)\n",
        "X_encoded = np.asarray(X_encoded)\n",
        "X_encoded = X_encoded[0,:, :]\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for label in np.unique(y):\n",
        "    plt.scatter(X_encoded[y_train==label, 0],\n",
        "                X_encoded[y_train==label, 1],\n",
        "                label=str(labels[int(label)]))\n",
        "# plt.title(\"Training data on 2 dimensions\")\n",
        "# plt.colorbar()\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4Ez23tN0PnU"
      },
      "source": [
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "X_test_encoded = encoder.predict(X_test_reshape)\n",
        "X_test_encoded = np.asarray(X_test_encoded)\n",
        "X_test_encoded = X_test_encoded[0,:, :]\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for label in np.unique(y_val):\n",
        "    plt.scatter(X_test_encoded[y_test==label, 0],\n",
        "                X_test_encoded[y_test==label, 1], \n",
        "                label=str(labels[int(label)]))\n",
        "plt.legend()\n",
        "# plt.title(\"None churn Validation data - Latent vector\")\n",
        "# plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5F0TxD1bvRe"
      },
      "source": [
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "X_val_encoded = encoder.predict(X_val_reshape)\n",
        "X_val_encoded = np.asarray(X_val_encoded)\n",
        "X_val_encoded = X_val_encoded[0,:, :]\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for label in np.unique(y_val):\n",
        "    plt.scatter(X_val_encoded[y_val==label, 0],\n",
        "                X_val_encoded[y_val==label, 1], \n",
        "                label=str(labels[int(label)]))\n",
        "plt.legend()\n",
        "# plt.title(\"None churn Validation data - Latent vector\")\n",
        "# plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsOCb3iif0LX"
      },
      "source": [
        "## Adding Buzz 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4qQzp-wgAs_"
      },
      "source": [
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "X_encoded = encoder.predict(X_train_vn_reshape)\n",
        "X_encoded = np.asarray(X_encoded)\n",
        "X_encoded = X_encoded[0,:, :]\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for label in np.unique(y_train_vn):\n",
        "    plt.scatter(X_encoded[y_train_vn==label, 0],\n",
        "                X_encoded[y_train_vn==label, 1],\n",
        "                label=str(labels[int(label)]))\n",
        "# plt.title(\"Training data on 2 dimensions\")\n",
        "# plt.colorbar()\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4ueM6NngAtB"
      },
      "source": [
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "X_test_encoded = encoder.predict(X_test_vn_reshape)\n",
        "X_test_encoded = np.asarray(X_test_encoded)\n",
        "X_test_encoded = X_test_encoded[0,:, :]\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for label in np.unique(y_test_vn):\n",
        "    plt.scatter(X_test_encoded[y_test_vn==label, 0],\n",
        "                X_test_encoded[y_test_vn==label, 1], \n",
        "                label=str(labels[int(label)]))\n",
        "plt.legend()\n",
        "# plt.title(\"None churn Validation data - Latent vector\")\n",
        "# plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0DHXsZCgAtC"
      },
      "source": [
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "X_val_encoded = encoder.predict(X_val_vn_reshape)\n",
        "X_val_encoded = np.asarray(X_val_encoded)\n",
        "X_val_encoded = X_val_encoded[0,:, :]\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for label in np.unique(y_val_vn):\n",
        "    plt.scatter(X_val_encoded[y_val_vn==label, 0],\n",
        "                X_val_encoded[y_val_vn==label, 1], \n",
        "                label=str(labels[int(label)]))\n",
        "plt.legend()\n",
        "# plt.title(\"None churn Validation data - Latent vector\")\n",
        "# plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}